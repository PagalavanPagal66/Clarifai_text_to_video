{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0e3a4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAT = '29d9803eb6f34718ba01d597a4a4e3b5'\n",
    "USER_ID = 'meta'\n",
    "APP_ID = 'Llama-2'\n",
    "MODEL_ID = 'llama2-13b-chat'\n",
    "MODEL_VERSION_ID = '79a1af31aa8249a99602fc05687e8f40'\n",
    "\n",
    "import streamlit as st\n",
    "\n",
    "storyname = st.text_input(\"ENTER PROMPT : \")\n",
    "\n",
    "if(st.button(\"SUBMIT\")):\n",
    "    prompt = \"\"\"\n",
    "    Generate a compelling video story script about \"\"\" + storyname + \"\"\". For each sentence in the story, provide a related visual image scene description to enhance the storytelling. Remember to format the output as follows: Image Prompt: [Insert image description or scene here] Narrator: [Write the narration or dialogue for the sentence] Image Prompt: [Insert image description or scene here] Narrator: [Write the narration or dialogue for the sentence] and so on untill the end of the story\"\"\"\n",
    "    \n",
    "    from clarifai_grpc.channel.clarifai_channel import ClarifaiChannel\n",
    "    from clarifai_grpc.grpc.api import resources_pb2, service_pb2, service_pb2_grpc\n",
    "    from clarifai_grpc.grpc.api.status import status_code_pb2\n",
    "    \n",
    "    channel = ClarifaiChannel.get_grpc_channel()\n",
    "    stub = service_pb2_grpc.V2Stub(channel)\n",
    "    \n",
    "    metadata = (('authorization', 'Key ' + PAT),)\n",
    "    \n",
    "    userDataObject = resources_pb2.UserAppIDSet(user_id=USER_ID, app_id=APP_ID)\n",
    "    \n",
    "    post_model_outputs_response = stub.PostModelOutputs(\n",
    "        service_pb2.PostModelOutputsRequest(\n",
    "            user_app_id=userDataObject,\n",
    "            model_id=MODEL_ID,\n",
    "            version_id=MODEL_VERSION_ID,\n",
    "            inputs=[\n",
    "                resources_pb2.Input(\n",
    "                    data=resources_pb2.Data(\n",
    "                        text=resources_pb2.Text(\n",
    "                            raw=prompt\n",
    "                        )\n",
    "                    )\n",
    "                )\n",
    "            ]\n",
    "        ),\n",
    "        metadata=metadata\n",
    "    )\n",
    "    if post_model_outputs_response.status.code != status_code_pb2.SUCCESS:\n",
    "        print(post_model_outputs_response.status)\n",
    "        raise Exception(f\"Post model outputs failed, status: {post_model_outputs_response.status.description}\")\n",
    "    \n",
    "    # Since we have one input, one output will exist here\n",
    "    output = post_model_outputs_response.outputs[0]\n",
    "    \n",
    "    st.write(\"Completion:\\n\")\n",
    "    st.write(output.data.text.raw)\n",
    "    prompt_text = output.data.text.raw\n",
    "    splitted_prompts = prompt_text.split('Image Prompt: ')\n",
    "    print(splitted_prompts)\n",
    "    image_prompt = []\n",
    "    narrator_prompt = []\n",
    "    for iter in splitted_prompts:\n",
    "        values = iter.split('Narrator:')\n",
    "        image_prompt.append((values[0]).split('.\\\\n\\\\n')[0])\n",
    "        try:\n",
    "            narrator_prompt_text = (values[1]).split('.\\\\n\\\\n')\n",
    "            narrator_prompt.append(narrator_prompt_text[0])\n",
    "        except:\n",
    "            pass\n",
    "    st.title(\"IMAGES : \")\n",
    "    for iter in image_prompt:\n",
    "        st.write(iter)\n",
    "    st.title(\"NARRATOR\")\n",
    "    for iter in narrator_prompt:\n",
    "        st.write(iter)\n",
    "    PAT = '29d9803eb6f34718ba01d597a4a4e3b5'\n",
    "    USER_ID = 'stability-ai'\n",
    "    APP_ID = 'stable-diffusion-2'\n",
    "    MODEL_ID = 'stable-diffusion-xl'\n",
    "    MODEL_VERSION_ID = '0c919cc1edfc455dbc96207753f178d7'\n",
    "    TEXT_FILE_URL = 'https://samples.clarifai.com/negative_sentence_12.txt'\n",
    "    from clarifai_grpc.channel.clarifai_channel import ClarifaiChannel\n",
    "    from clarifai_grpc.grpc.api import resources_pb2, service_pb2, service_pb2_grpc\n",
    "    from clarifai_grpc.grpc.api.status import status_code_pb2\n",
    "    channel = ClarifaiChannel.get_grpc_channel()\n",
    "    stub = service_pb2_grpc.V2Stub(channel)\n",
    "    metadata = (('authorization', 'Key ' + PAT),)\n",
    "    userDataObject = resources_pb2.UserAppIDSet(user_id=USER_ID, app_id=APP_ID)\n",
    "    post_model_outputs_response = stub.PostModelOutputs(\n",
    "        service_pb2.PostModelOutputsRequest(\n",
    "            user_app_id=userDataObject,\n",
    "            model_id=MODEL_ID,\n",
    "            version_id=MODEL_VERSION_ID,\n",
    "            inputs=[\n",
    "                resources_pb2.Input(\n",
    "                    data=resources_pb2.Data(\n",
    "                        text=resources_pb2.Text(\n",
    "                            raw = \"A person doing yoga poses on a serene beach at sunrise.\"\n",
    "                        )\n",
    "                    )\n",
    "                )\n",
    "            ]\n",
    "        ),\n",
    "        metadata=metadata\n",
    "    )\n",
    "    if post_model_outputs_response.status.code != status_code_pb2.SUCCESS:\n",
    "        print(post_model_outputs_response.status)\n",
    "        raise Exception(\"Post model outputs failed, status: \" + post_model_outputs_response.status.description)\n",
    "    output = post_model_outputs_response.outputs[0]\n",
    "    print(\"Predicted concepts:\")\n",
    "    for concept in output.data.concepts:\n",
    "        print(\"%s %.2f\" % (concept.name, concept.value))\n",
    "    base64_image = output.data.image.base64\n",
    "    with open(\"Clarifai_image.jpg\",'wb') as f:\n",
    "        f.write(base64_image)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9efbab6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'streamlit'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mstreamlit\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mst\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mclarifai_grpc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchannel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclarifai_channel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ClarifaiChannel\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mclarifai_grpc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgrpc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m resources_pb2, service_pb2, service_pb2_grpc\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'streamlit'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a95282",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
